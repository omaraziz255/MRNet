{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PaperImplementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNb6Ka49mA6Zs9enRgNaLJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omaraziz255/MRNet/blob/master/PaperImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDqNP6S9oDlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive, files\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models,layers,losses,optimizers, backend\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy import ndimage as nd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Convolution2D, BatchNormalization, Activation,DepthwiseConv2D, Input, Dense, GlobalAveragePooling2D, Dropout, Flatten, Reshape, MaxPooling2D, MaxPooling1D, GlobalMaxPooling1D, GlobalMaxPooling2D\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.metrics import binary_accuracy, mae\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "import warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDdCx_7eoZY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backend.set_image_data_format('channels_first')\n",
        "drive.mount('/content/gdrive/')\n",
        "base_path = \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZDUsCQEo5-_",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction using base VGG19 model and pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grnxDvcP1tFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_extractor(base_path, plane, base_model, pooling_model, save_path):\n",
        "   path = base_path + \"/\" + plane\n",
        "   save_path = save_path + \"/\" + plane\n",
        "   files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "   for f in files:\n",
        "     temp = np.load(path + \"/\" + f)\n",
        "     temp = np.stack([temp]*3, axis=1)\n",
        "     print(temp.shape)\n",
        "     slices = temp.shape[0]\n",
        "\n",
        "     X_train = Input((slices,512))\n",
        "     train = BatchNormalization()(X_train)\n",
        "     train = GlobalMaxPooling1D()(train)\n",
        "     train = Flatten()(train)\n",
        "\n",
        "     final = models.Model(inputs=X_train, outputs=train)\n",
        "\n",
        "     features = base_model.predict(temp)\n",
        "     print(features.shape)\n",
        "     output = pooling_model.predict(features)\n",
        "     predictions = final.predict(output.reshape((1,slices,512)))\n",
        "     print(output.shape)\n",
        "     print(predictions.shape)\n",
        "\n",
        "     np.save(save_path + \"/\" + f, predictions)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE3cBQCnSGe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = VGG19(weights='imagenet',include_top=False, input_shape=(3,256,256))\n",
        "\n",
        "features = Input((512,8,8))\n",
        "gap = GlobalAveragePooling2D()(features)\n",
        "pooling_model = models.Model(inputs=features, outputs=gap)\n",
        "\n",
        "feature_extractor(base_path+\"Dataset/TestSet/\", \"coronal\", base_model, pooling_model, base_path+\"Features/TestSet/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rZQNjEAq7Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_mrnet(base_path, plane, label, model):\n",
        "  total = base_path + \"/\" + plane\n",
        "  Y_train = np.load(\"/content/gdrive/My Drive/Dataset/TrainingSet/\" + label + \".npy\")[:,1]\n",
        "  files = [f for f in sorted(os.listdir(total)) if f.endswith(\".npy\")]\n",
        "  X_train = None\n",
        "  mc = ModelCheckpoint('/content/gdrive/My Drive/Models/MRNET_'+plane+'_'+label+'.h5', monitor='val_accuracy', mode='max', verbose=2, save_best_only=True)\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=10)\n",
        "  lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                         patience=5, min_lr=0.0001)\n",
        "\n",
        "  for f in files:\n",
        "    temp = np.load(total + \"/\" + f)\n",
        "    if X_train is None:\n",
        "      X_train = temp\n",
        "    else:\n",
        "      X_train = np.vstack((X_train, temp))\n",
        "  print(X_train.shape)\n",
        "\n",
        "  X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.1, shuffle=True)\n",
        "\n",
        "  weights = class_weight.compute_class_weight('balanced',np.unique(Y_train), Y_train)\n",
        "  class_weights = dict(enumerate(weights))\n",
        "  validation_weights = class_weight.compute_sample_weight('balanced', Y_valid)\n",
        "\n",
        "  history = model.fit(X_train,Y_train, batch_size=1,\n",
        "                      validation_data=(X_valid, Y_valid, validation_weights),\n",
        "                      epochs = 100, callbacks = [mc, es, lr], verbose=2, class_weight = class_weights)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHrj7_qppJ-V",
        "colab_type": "text"
      },
      "source": [
        "# Passing features to dense layers for final classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgHhiAGo0Oh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input((512))\n",
        "model = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001))(inputs)\n",
        "model = Dropout(0.5)(model)\n",
        "model = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001))(model)\n",
        "model = Dropout(0.5)(model)\n",
        "pred = Dense(1,activation='sigmoid')(model)\n",
        "mrnet = models.Model(inputs=inputs,outputs=pred)\n",
        "\n",
        "adam = optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "mrnet.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])  #Should've been F1_score and Recall\n",
        "\n",
        "train_mrnet(base_path + \"Features/TrainingSet\", \"sagittal\", \"abnormal\", mrnet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w72ZouCfzRae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def load_test(path):\n",
        "  files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "  X_test = None\n",
        "  for f in files:\n",
        "    temp = np.load(path + \"/\" + f)\n",
        "    if X_test is None:\n",
        "      X_test = temp\n",
        "    else:\n",
        "      X_test = np.vstack((X_test, temp))\n",
        "  \n",
        "  return X_test\n",
        "\n",
        "\n",
        "\n",
        "def ensemble_evaluate(modelname,label):\n",
        "  planes = [\"axial\", \"coronal\", \"sagittal\"]\n",
        "  plane_predictions = None\n",
        "  weights = []\n",
        "  Y_test = np.load(\"/content/gdrive/My Drive/Dataset/TestSet/\" + label + \".npy\")[:,1]\n",
        "  for i,plane in enumerate(planes):\n",
        "    print(\"Predicting plane: \" + plane)\n",
        "    # print(\"Loading Model\")\n",
        "    model = models.load_model(\"/content/gdrive/My Drive/Models/\"+modelname+\"_\"+plane+\"_\"+label+\".h5\")\n",
        "    # print(\"Loading Data\")\n",
        "    X_test = load_test(\"/content/gdrive/My Drive/Features/TestSet/\"+plane)\n",
        "    # print(\"Evaluating\")\n",
        "    weights.append(model.evaluate(X_test, Y_test, verbose=0)[1])\n",
        "    predictions = (model.predict(X_test)>0.5).astype(np.int_).ravel()\n",
        "    # print(\"Predicting\")\n",
        "    if plane_predictions is None:\n",
        "      plane_predictions = predictions\n",
        "    else:\n",
        "      plane_predictions = np.vstack((plane_predictions, predictions))\n",
        "    # print(plane_predictions.shape)\n",
        "\n",
        "  weighted_predictions = np.arange(plane_predictions.shape[1])\n",
        "  weights = np.array(weights)\n",
        "  for i in range(plane_predictions.shape[1]):\n",
        "    weighted_predictions[i] = np.argmax(np.bincount(np.array([plane_predictions[0][i], plane_predictions[1][i], plane_predictions[2][i]]),weights))\n",
        "  \n",
        "\n",
        "  ground_truth = np.load(\"/content/gdrive/My Drive/Dataset/TestSet/\"+label+\".npy\")[:,1]\n",
        "\n",
        "  print(\"Accuracy of \" + modelname + \" model with \" + label + \" label: \")\n",
        "  print(accuracy_score(ground_truth, weighted_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "134qn6X71uNK",
        "colab_type": "code",
        "outputId": "cf7d26dc-8844-4956-b6ba-6c1e18ab4178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"MRNET\",\"abnormal\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of MRNET model with abnormal label: \n",
            "0.8416666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7jQYJYI10zz",
        "colab_type": "code",
        "outputId": "2a5a348a-2590-463e-f102-64d1c990f4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"MRNET\",\"acl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of MRNET model with acl label: \n",
            "0.6083333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEwSmuan15T4",
        "colab_type": "code",
        "outputId": "a3cbd68d-2b87-4159-c260-578fdd692780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"MRNET\",\"meniscus\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of MRNET model with meniscus label: \n",
            "0.6916666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}