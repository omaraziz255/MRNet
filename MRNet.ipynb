{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7KoH3Ai_ZVu",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvdEOWWFzg5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive, files\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models,layers,losses,optimizers, backend\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.utils import class_weight\n",
        "from scipy import ndimage as nd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Convolution2D, BatchNormalization, Activation,DepthwiseConv2D, Input, Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.metrics import binary_accuracy, mae\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import warnings\n",
        "backend.set_image_data_format('channels_last')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYwYqLJKz0ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BYy77yblL6m",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the dataset and saving it to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8XgxeoF0Tzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget http://download.cs.stanford.edu/deep/MRNet-v1.0.zip\n",
        "# !unzip -qq \"MRNet-v1.0.zip\" -d \"/content/gdrive/My Drive/MRNetDataset/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJIWaglSlXDR",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUOOaXpolcCJ",
        "colab_type": "text"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27t-3iKVu6FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG16\n",
        "def vgg16():\n",
        "  VGG16 = models.Sequential()\n",
        "\n",
        "  VGG16.add(layers.Conv2D(input_shape=(256,256,3), filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "  VGG16.add(layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "\n",
        "  VGG16.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "  VGG16.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "  VGG16.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "\n",
        "  VGG16.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "  VGG16.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "  VGG16.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "\n",
        "  VGG16.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "  VGG16.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "  VGG16.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "  VGG16.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "\n",
        "  VGG16.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "  VGG16.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "  VGG16.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "  VGG16.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "  VGG16.add(Dropout(0.2))\n",
        "\n",
        "  VGG16.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "  VGG16.add(layers.Flatten())\n",
        "\n",
        "  VGG16.add(layers.Dense(units=4096, activation='relu'))\n",
        "  VGG16.add(Dropout(0.5))\n",
        "  VGG16.add(layers.Dense(units=4096, activation='relu'))\n",
        "  VGG16.add(Dropout(0.5))\n",
        "  VGG16.add(layers.Dense(units=1000, activation='relu'))\n",
        "  VGG16.add(Dropout(0.5))\n",
        "  VGG16.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  SGD = optimizers.SGD(learning_rate=0.1) #default learning rate is 0.001\n",
        "  VGG16.compile(optimizer= SGD, loss = losses.binary_crossentropy, metrics=['accuracy']) #Should be F1_Score / Recall\n",
        "\n",
        "  return VGG16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G91QVg1NlisJ"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4fnZY-D6QWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ResNet\n",
        "#Can't use Sequential model because we need to skip connections\n",
        "\n",
        "def add_shortcut(X, f, downsample=False):\n",
        "  shortcut = X\n",
        "  if downsample:\n",
        "    s = (2,2)\n",
        "    shortcut = layers.Conv2D(filters=f, kernel_size=(3,3), strides=s, padding='same')(shortcut) \n",
        "    #need to revise padding to make sure input tensors are sized correctly #TODO\n",
        "    shortcut = layers.BatchNormalization(axis = 3)(shortcut)\n",
        "  else:\n",
        "    s = (1,1)\n",
        "\n",
        "  X = layers.Conv2D(filters=f, kernel_size=(3,3), strides=s, padding='same')(X)\n",
        "  X = layers.BatchNormalization(axis = 3)(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = layers.Conv2D(filters=f, kernel_size=(3,3), padding='same')(X)\n",
        "  X = layers.BatchNormalization(axis = 3)(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = layers.Add()([X, shortcut])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        "\n",
        "\n",
        "\n",
        "def resnet():\n",
        "  inputLayer = layers.Input((256,256,3))\n",
        "  X = layers.ZeroPadding2D((3,3))(inputLayer)\n",
        "  X = layers.Conv2D(filters=64, kernel_size=(7,7), strides=(2,2))(X)\n",
        "  X = layers.BatchNormalization(axis = 3)(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "  X = layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "  for _ in range(3):\n",
        "    X = add_shortcut(X, 64)\n",
        "\n",
        "  X = add_shortcut(X, 128, downsample = True)\n",
        "  for _ in range(2):\n",
        "    X = add_shortcut(X, 128)\n",
        "\n",
        "  X = add_shortcut(X, 256, downsample = True)\n",
        "  for _ in range(2):\n",
        "    X = add_shortcut(X, 256)\n",
        "\n",
        "  X = add_shortcut(X, 512, downsample = True)\n",
        "  for _ in range(2):\n",
        "    X = add_shortcut(X, 512)\n",
        "\n",
        "  X = layers.AveragePooling2D((3, 3), strides=(2, 2))(X)\n",
        "  X = layers.Flatten()(X)\n",
        "  X = layers.Dense(units=1, activation='sigmoid')(X)\n",
        "\n",
        "  ResNet = models.Model(inputs=inputLayer, outputs=X)\n",
        "\n",
        "  SGD = optimizers.SGD(learning_rate = 0.1) #default learning rate is 0.001\n",
        "  ResNet.compile(optimizer= SGD, loss = losses.binary_crossentropy, metrics=['accuracy'])\n",
        "  return ResNet\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nIBk4ewl_2Y",
        "colab_type": "text"
      },
      "source": [
        "## InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRD0nkvtgf-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#InceptionV3\n",
        "\n",
        "def createBranch(X, f, k, p='same', s=(1,1)):\n",
        "  X = layers.Conv2D(filters=f, kernel_size=k, strides=s, padding=p, kernel_regularizer=l2(0.01))(X)\n",
        "  X = layers.BatchNormalization(axis = 3)(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "  return X\n",
        "\n",
        "def inception():\n",
        "\n",
        "  inputLayer = layers.Input((256,256,3))\n",
        "  X = createBranch(inputLayer, 32, (3,3), p='valid')\n",
        "  X = createBranch(X, 64, (3,3))\n",
        "  X = layers.MaxPooling2D((3,3), strides=(2,2))(X)\n",
        "\n",
        "  X = createBranch(X, 80, (1, 1), p='valid')\n",
        "  X = createBranch(X, 192, (3, 3), p='valid')\n",
        "  X = layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "  B1 = createBranch(X, 64, (1, 1))\n",
        "\n",
        "  B5 = createBranch(X, 48, (1, 1))\n",
        "  B5 = createBranch(B5, 64, (5, 5))\n",
        "\n",
        "  B3 = createBranch(X, 64, (1, 1))\n",
        "  B3 = createBranch(B3, 96, (3, 3))\n",
        "  B3 = createBranch(B3, 96, (3, 3))\n",
        "\n",
        "  Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(X)\n",
        "  Pool = createBranch(Pool, 32, (1, 1))\n",
        "  X = layers.concatenate([B1, B5, B3, Pool],axis=3)\n",
        "\n",
        "\n",
        "\n",
        "  B1 = createBranch(X, 64, (1, 1))\n",
        "\n",
        "  B5 = createBranch(X, 48, (1, 1))\n",
        "  B5 = createBranch(B5, 64, (5, 5))\n",
        "\n",
        "  B3 = createBranch(X, 64, (1, 1))\n",
        "  B3 = createBranch(B3, 96, (3, 3))\n",
        "  B3 = createBranch(B3, 96, (3, 3))\n",
        "\n",
        "  Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(X)\n",
        "  Pool = createBranch(Pool, 64, (1, 1))\n",
        "  X = layers.concatenate([B1, B5, B3, Pool],axis=3)\n",
        "\n",
        "\n",
        "  B1 = createBranch(X, 64, (1, 1))\n",
        "\n",
        "  B5 = createBranch(X, 48, (1, 1))\n",
        "  B5 = createBranch(B5, 64, (5, 5))\n",
        "\n",
        "  B3 = createBranch(X, 64, (1, 1))\n",
        "  B3 = createBranch(B3, 96, (3, 3))\n",
        "  B3 = createBranch(B3, 96, (3, 3))\n",
        "\n",
        "  Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(X)\n",
        "  Pool = createBranch(Pool, 64, (1, 1))\n",
        "  X = layers.concatenate([B1, B5, B3, Pool],axis=3)\n",
        "\n",
        "\n",
        "  B3 = createBranch(X, 384, (3, 3), s=(2, 2), p='valid')\n",
        "\n",
        "  B3branch = createBranch(X, 64, (1, 1))\n",
        "  B3branch = createBranch(B3branch, 96, (3, 3))\n",
        "  B3branch = createBranch(B3branch, 96, (3, 3), s=(2, 2), p='valid')\n",
        "\n",
        "  Pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "  X = layers.concatenate([B3, B3branch, Pool], axis=3)\n",
        "\n",
        "\n",
        "\n",
        "  B1 = createBranch(X, 192, (1, 1))\n",
        "\n",
        "  B7 = createBranch(X, 128, (1, 1))\n",
        "  B7 = createBranch(B7, 128, (1, 7))\n",
        "  B7 = createBranch(B7, 192, (7, 1))\n",
        "\n",
        "  B7branch = createBranch(X, 128, (1, 1))\n",
        "  B7branch = createBranch(B7branch, 128, (7, 1))\n",
        "  B7branch = createBranch(B7branch, 128, (1, 7))\n",
        "  B7branch = createBranch(B7branch, 128, (7, 1))\n",
        "  B7branch = createBranch(B7branch, 192, (1, 7))\n",
        "\n",
        "  Pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(X)\n",
        "  Pool = createBranch(Pool, 192, (1, 1))\n",
        "\n",
        "  X = layers.concatenate([B1, B7, B7branch, Pool],axis=3)\n",
        "\n",
        "\n",
        "  X = layers.GlobalAveragePooling2D()(X)\n",
        "  X = layers.Dense(units=1, activation='sigmoid')(X)\n",
        "\n",
        "  Inception = models.Model(inputs=inputLayer, outputs=X)\n",
        "  SGD = optimizers.SGD(learning_rate=0.1) #default learning rate is 0.001\n",
        "  Inception.compile(optimizer= SGD, loss = losses.binary_crossentropy, metrics=['accuracy']) \n",
        "\n",
        "  return Inception\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMljI2jFmEIe",
        "colab_type": "text"
      },
      "source": [
        "## MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "946i2o7WxGRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MobileNet\n",
        "\n",
        "def mobilenet():\n",
        "\n",
        "  inputLayer = Input((256,256, 3))\n",
        "\n",
        "  X = Convolution2D(32, (3, 3), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(inputLayer)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(64, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(128, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(128, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(256, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(256, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(512, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(1024, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Convolution2D(1024, (1, 1), strides=(1, 1), padding='same', use_bias=False, kernel_regularizer=l2(0.01))(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Dropout(0.2)(X)\n",
        "\n",
        "  X = GlobalAveragePooling2D()(X)\n",
        "  X = Dense(units=1, activation='sigmoid', kernel_regularizer=l2(0.01))(X)\n",
        "\n",
        "  MobileNet = models.Model(inputs=inputLayer, outputs=X)\n",
        "  SGD = optimizers.SGD(learning_rate=0.1) #default learning rate is 0.001\n",
        "  MobileNet.compile(optimizer= SGD, loss = losses.binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "  return MobileNet\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgQDmLlomVZz",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrSl16-Ia9VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "warnings.simplefilter('ignore')\n",
        "def model_train(basepath, plane, modelname, label):\n",
        "  path = basepath + \"/\" + plane\n",
        "  files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "  count = 10\n",
        "  labels = np.load(basepath + \"/\" + label + \".npy\")[:,1]\n",
        "  print(labels.shape)\n",
        "  mc = ModelCheckpoint(\"/content/gdrive/My Drive/Models/\"+modelname+\"_\"+plane+\"_\"+label+\".h5\", monitor='val_accuracy',mode='max', save_best_only=True)\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=5)\n",
        "  lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=6, min_lr=0.0001)\n",
        "  batch = 32\n",
        "  stride = 113\n",
        "  validation = None\n",
        "  for i in range(1,count):\n",
        "    print(i)\n",
        "    pre_process = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "    pre_process_valid = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "    X_train = None\n",
        "    Y_train = None\n",
        "    cases= files[(i*stride):(i*stride)+stride]\n",
        "    for j,filename in enumerate(cases):\n",
        "      totalpath = path + \"/\" + filename\n",
        "      temp = np.load(totalpath)\n",
        "      if X_train is None:\n",
        "        X_train = temp\n",
        "        Y_train = np.repeat(labels[(i*stride)+j], temp.shape[0])\n",
        "      else:\n",
        "        X_train = np.vstack((X_train, temp))\n",
        "        Y_train = np.append(Y_train, np.repeat(labels[(i*stride)+j], temp.shape[0]))\n",
        "\n",
        "    print(Y_train.shape)\n",
        "    X_train = np.array(X_train).reshape((len(X_train),256,256))\n",
        "    print(X_train.shape)\n",
        "\n",
        "    X_train =np.stack([X_train]*3,axis=3)\n",
        "\n",
        "    X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.1, shuffle=True)\n",
        "\n",
        "\n",
        "    if validation is None:\n",
        "      validation = X_valid\n",
        "      validation_labels = Y_valid\n",
        "    else:\n",
        "      validation = np.vstack((validation, X_valid))\n",
        "      validation_labels = np.append(validation_labels, Y_valid)\n",
        "\n",
        "      \n",
        "    pre_process_valid.fit(validation)\n",
        "    pre_process.fit(X_train)\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(Y_train.shape)\n",
        "\n",
        "    try:\n",
        "      model = models.load_model(\"/content/gdrive/My Drive/Models/\"+modelname+\"_\"+plane+\"_\"+label+\".h5\")\n",
        "      print(\"Loading Model\")\n",
        "    except OSError:\n",
        "      print(\"Generating new Model\")\n",
        "      model = model_gen(modelname)\n",
        "\n",
        "    weights = class_weight.compute_class_weight('balanced',np.unique(Y_train), Y_train)\n",
        "    class_weights = dict(enumerate(weights))\n",
        "    validation_weights = class_weight.compute_sample_weight('balanced', validation_labels)\n",
        "  \n",
        "\n",
        "    history = model.fit(pre_process.flow(X_train,Y_train, batch_size=batch),\n",
        "                        validation_data=pre_process_valid.flow(validation, validation_labels),\n",
        "                        class_weight = class_weights,epochs = 50, validation_steps = len(validation)/batch,\n",
        "                        callbacks = [mc, es, lr], steps_per_epoch = len(X_train)/batch)\n",
        "\n",
        "def model_gen(modelname):\n",
        "  return eval(modelname+\"()\")\n",
        "\n",
        "model_train(\"/content/gdrive/My Drive/Dataset/TrainingSet\",\"axial\",\"resnet\", \"meniscus\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSzgSW2rmig1",
        "colab_type": "text"
      },
      "source": [
        "## Our Approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uWvwFADsFOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def define_labels():   #Generating Mutually Exclusive Labels to account for intersections between the 3 original ones (Didn't produce promising results)\n",
        "  base_path = \"/content/gdrive/My Drive/Dataset/\"\n",
        "  path = base_path + \"TrainingSet/\"\n",
        "  # valid_path = base_path + \"ValidationSet/\"\n",
        "  # test_path = base_path + \"TestSet/\"\n",
        "  abnormal = np.load(path+\"abnormal.npy\")\n",
        "  acl = np.load(path+\"acl.npy\")\n",
        "  meniscus = np.load(path+\"meniscus.npy\")\n",
        "  cases = abnormal.shape[0]\n",
        "  classes = np.zeros((cases, 5))\n",
        "  for i in range(cases):\n",
        "      if(abnormal[i,1] == 1 and acl[i,1] == 1 and meniscus[i,1] == 1):\n",
        "        classes[i,4] = 1\n",
        "      elif(abnormal[i,1] == 1 and meniscus[i,1] == 1):\n",
        "        classes[i,3] = 1\n",
        "      elif(abnormal[i,1] == 1 and acl[i,1] == 1):\n",
        "        classes[i,2] = 1\n",
        "      elif(abnormal[i,1] == 1):\n",
        "        classes[i,1] = 1\n",
        "      elif(abnormal[i,1] == 0 and acl[i,1] == 0 and meniscus[i,1] == 0):\n",
        "        classes[i,0] = 1\n",
        "  np.save(path+\"total.npy\",classes)\n",
        "  \n",
        "\n",
        "def load_dataset(basepath, plane):   #Using each case as a datapoint, padding each case to ensure constant tensor shape\n",
        "  MAX = 61 #max number of slices\n",
        "  path = basepath + \"/\" + plane\n",
        "  files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "  dataset = []\n",
        "  for filename in files:\n",
        "    totalpath = path + \"/\" + filename\n",
        "    temp = np.load(totalpath)\n",
        "    temp = 1/255*temp\n",
        "    pad = MAX - temp.shape[0]\n",
        "    for _ in range(pad):\n",
        "      temp = np.vstack((temp, temp[-1,:,:].reshape((1,256,256))))\n",
        "    dataset.append(temp)\n",
        "  \n",
        "  size = len(dataset)\n",
        "  dataset = np.array(dataset)\n",
        "  dataset = np.swapaxes(dataset, 1,2)\n",
        "  dataset = np.swapaxes(dataset, 2,3)\n",
        "  # np.save(basepath+\"/\"+plane.upper()+\".npy\", dataset)\n",
        "\n",
        "  \n",
        "  \n",
        "  print(dataset.shape)\n",
        "  return dataset\n",
        "\n",
        "def load_interdataset(basepath,plane):  #interpolating across slices of each case, was unrealistic in the given time limit\n",
        "  MIN = 19\n",
        "  path = basepath + \"/\" + plane\n",
        "  files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "  dataset = []\n",
        "  for filename in files:\n",
        "    totalpath = path + \"/\" + filename\n",
        "    temp = np.load(totalpath)\n",
        "    factors = [w/float(f) for w,f in zip([MIN,256,256], temp.shape)]\n",
        "    interpolated_scan = nd.interpolation.zoom(temp, zoom=factors)\n",
        "    dataset.append(interpolated_scan)\n",
        "  \n",
        "  \n",
        "  dataset = np.array(dataset)\n",
        "  dataset = np.swapaxes(dataset, 1,2)\n",
        "  dataset = np.swapaxes(dataset, 2,3)\n",
        "\n",
        "  print(dataset.shape)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def load_reducedDataset(basepath, plane):  #using 3 slices from each case (Not enough data, too many epochs needed)\n",
        "  path = basepath + \"/\" + plane\n",
        "  files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "  dataset = []\n",
        "  for filename in files:\n",
        "    totalpath = path + \"/\" + filename\n",
        "    temp = np.load(totalpath)\n",
        "    mid_slice = temp.shape[0]//2\n",
        "    case = np.array([temp[mid_slice-5], temp[mid_slice], temp[mid_slice+5]])\n",
        "    dataset.append(case)\n",
        "\n",
        "  dataset = np.array(dataset)\n",
        "  dataset = np.swapaxes(dataset, 1,2)\n",
        "  dataset = np.swapaxes(dataset, 2,3)\n",
        "\n",
        "  print(dataset.shape)\n",
        "  return dataset\n",
        "\n",
        "def load_large(base_path, labels, plane):  #considering each slice as a datapoint as specified in the requirements\n",
        "    path = base_path + \"/\" + plane\n",
        "    files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "    labels = np.load(base_path + \"/\" + labels + \".npy\")[:,1]\n",
        "    Y = None\n",
        "    X = None\n",
        "    for i,filename in enumerate(files):\n",
        "      totalpath = path + \"/\" + filename\n",
        "      temp = np.load(totalpath)\n",
        "      if X is None:\n",
        "        X = temp\n",
        "        Y = np.repeat(labels[i], temp.shape[0])\n",
        "      else:\n",
        "        X = np.vstack((X, temp))\n",
        "        Y = np.append(Y, np.repeat(labels[i], temp.shape[0]))\n",
        "    return X, Y\n",
        "  \n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XR8o5mTnzK7",
        "colab_type": "text"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuKWUPopMgPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def load_test(basepath, plane, label):\n",
        "  path = basepath + \"/\" + plane\n",
        "  files = [f for f in sorted(os.listdir(path)) if f.endswith(\".npy\")]\n",
        "  slices = []\n",
        "  X = None\n",
        "  Y= None\n",
        "  labels = np.load(basepath+\"/\"+label+\".npy\")[:,1]\n",
        "  for i,filename in enumerate(files):\n",
        "    totalpath = path + \"/\" + filename\n",
        "    temp = np.load(totalpath)\n",
        "    slices.append(temp.shape[0])\n",
        "    if X is None:\n",
        "      X = temp\n",
        "      Y = np.repeat(labels[i], temp.shape[0])\n",
        "    else:\n",
        "      X = np.vstack((X, temp))\n",
        "      Y = np.append(Y, np.repeat(labels[i], temp.shape[0]))\n",
        "  \n",
        "  X =np.stack([X]*3,axis=3) #This is because axial models were not trained with RGB stacking\n",
        "  return X, Y, slices\n",
        "    \n",
        "\n",
        "def predict_case(preds, slices):\n",
        "  i = 0\n",
        "  finals = []\n",
        "  for case in slices:\n",
        "    final = round(np.sum(preds[i:i+case])/case)\n",
        "    finals.append(final)\n",
        "    i += case\n",
        "  # print(len(finals))\n",
        "  return np.array(finals).astype(np.int_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ensemble(model, label):\n",
        "  axial_model = models.load_model(\"/content/gdrive/My Drive/Models/\"+model+\"_axial_\"+label+\".h5\")\n",
        "  coronal_model = models.load_model(\"/content/gdrive/My Drive/Models/\"+model+\"_coronal_\"+label+\".h5\")\n",
        "  sagittal_model = models.load_model(\"/content/gdrive/My Drive/Models/\"+model+\"_sagittal_\"+label+\".h5\")\n",
        "\n",
        "  X_coronal, Y_coronal, slices_coronal = load_test(\"/content/gdrive/My Drive/Dataset/TestSet\", \"coronal\", label)\n",
        "  X_sagittal, Y_sagittal, slices_sagittal = load_test(\"/content/gdrive/My Drive/Dataset/TestSet\", \"sagittal\", label)\n",
        "  X_axial, Y_axial, slices_axial = load_test(\"/content/gdrive/My Drive/Dataset/TestSet\", \"axial\", label)\n",
        "\n",
        "  w1 = axial_model.evaluate(X_axial, Y_axial)[1]\n",
        "  axial_predictions = (axial_model.predict(X_axial) > 0.5).astype(np.int_).ravel()\n",
        "\n",
        "  axial_predictions = predict_case(axial_predictions, slices_axial)\n",
        "\n",
        "  w2 = coronal_model.evaluate(X_coronal, Y_coronal)[1]\n",
        "  coronal_predictions = (coronal_model.predict(X_coronal) > 0.5).astype(np.int_).ravel()\n",
        "\n",
        "  coronal_predictions = predict_case(coronal_predictions, slices_coronal)\n",
        "\n",
        "  w3 = sagittal_model.evaluate(X_sagittal, Y_sagittal)[1]\n",
        "  sagittal_predictions = (sagittal_model.predict(X_sagittal) > 0.5).astype(np.int_).ravel()\n",
        "\n",
        "  sagittal_predictions = predict_case(sagittal_predictions, slices_sagittal)\n",
        "\n",
        "\n",
        "\n",
        "  print(axial_predictions.shape)\n",
        "  print(axial_predictions)\n",
        "  print(Y_axial)\n",
        "  print(coronal_predictions.shape)\n",
        "  print(sagittal_predictions.shape)\n",
        "\n",
        "\n",
        "def ensemble_evaluate(modelname,label):\n",
        "  planes = [\"axial\", \"coronal\", \"sagittal\"]\n",
        "  plane_predictions = None\n",
        "  weights = []\n",
        "  for i,plane in enumerate(planes):\n",
        "    print(\"Predicting plane: \" + plane)\n",
        "    # print(\"Loading Model\")\n",
        "    model = models.load_model(\"/content/gdrive/My Drive/Models/\"+modelname+\"_\"+plane+\"_\"+label+\".h5\")\n",
        "    # print(\"Loading Data\")\n",
        "    X_test, Y_test, slices = load_test(\"/content/gdrive/My Drive/Dataset/TestSet\", plane, label)\n",
        "    # print(\"Evaluating\")\n",
        "    weights.append(model.evaluate(X_test, Y_test, verbose=0)[1])\n",
        "    predictions = (model.predict(X_test)>0.5).astype(np.int_).ravel()\n",
        "    # print(\"Predicting\")\n",
        "    if plane_predictions is None:\n",
        "      plane_predictions = predict_case(predictions, slices)\n",
        "    else:\n",
        "      plane_predictions = np.vstack((plane_predictions, predict_case(predictions, slices)))\n",
        "    # print(plane_predictions.shape)\n",
        "\n",
        "  weighted_predictions = np.arange(plane_predictions.shape[1])\n",
        "  weights = np.array(weights)\n",
        "  for i in range(plane_predictions.shape[1]):\n",
        "    weighted_predictions[i] = np.argmax(np.bincount(np.array([plane_predictions[0][i], plane_predictions[1][i], plane_predictions[2][i]]),weights))\n",
        "  \n",
        "\n",
        "  ground_truth = np.load(\"/content/gdrive/My Drive/Dataset/TestSet/\"+label+\".npy\")[:,1]\n",
        "\n",
        "  print(\"Accuracy of \" + modelname + \" model with \" + label + \" label: \")\n",
        "  print(accuracy_score(ground_truth, weighted_predictions))\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSOisO4Yu0gP",
        "colab_type": "code",
        "outputId": "556ab19a-3aab-4b9a-cb9d-726fd01ccd18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"resnet\",\"abnormal\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of resnet model with abnormal label: \n",
            "0.7666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObfWtTY9vHYT",
        "colab_type": "code",
        "outputId": "4edbec68-a3ed-4c82-da8c-fbf2d4db751b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"resnet\",\"acl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of resnet model with acl label: \n",
            "0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0mUYeB7vHz_",
        "colab_type": "code",
        "outputId": "7f628693-2e7b-4a64-8db8-7bec504b98ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"resnet\",\"meniscus\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of resnet model with meniscus label: \n",
            "0.5666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKR_fe5bwSmO",
        "colab_type": "code",
        "outputId": "b837a215-5642-4e3a-9df0-8e41695466b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"inception\",\"abnormal\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of inception model with abnormal label: \n",
            "0.7916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDoEkd71wS4E",
        "colab_type": "code",
        "outputId": "dcaeef4e-3a7c-4db9-c0be-0b2f79e03b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"inception\",\"acl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of inception model with acl label: \n",
            "0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXFmPk_twS_j",
        "colab_type": "code",
        "outputId": "fe56a0c9-f1d6-43ae-dd31-c2e1fd150eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"inception\",\"meniscus\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of inception model with meniscus label: \n",
            "0.43333333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hktCsdg-t52-",
        "colab_type": "code",
        "outputId": "19313977-d07a-47ae-9b05-ed485b19a17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"vgg16\",\"abnormal\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of vgg16 model with abnormal label: \n",
            "0.7916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmYzAqCSt8W6",
        "colab_type": "code",
        "outputId": "73fca586-8194-43f6-9214-1d7645949121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"vgg16\",\"acl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of vgg16 model with acl label: \n",
            "0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwiAa_weuAYc",
        "colab_type": "code",
        "outputId": "c353117a-b315-466c-a37d-b91520374d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"vgg16\",\"meniscus\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of vgg16 model with meniscus label: \n",
            "0.5666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlBzuFUwtgH",
        "colab_type": "code",
        "outputId": "8ba4a4cb-c716-40c1-d51d-590fd9136114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"mobilenet\",\"abnormal\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of mobilenet model with abnormal label: \n",
            "0.7916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2zuD_Wdwu5c",
        "colab_type": "code",
        "outputId": "4e54156e-4e19-4c23-ff6f-f59429d770e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"mobilenet\",\"acl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of mobilenet model with acl label: \n",
            "0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDPTr51kwvFO",
        "colab_type": "code",
        "outputId": "3119710a-1749-4c28-9095-92cf1edd8710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"mobilenet\",\"meniscus\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of mobilenet model with meniscus label: \n",
            "0.43333333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_PejHR5xh79",
        "colab_type": "code",
        "outputId": "d5f44e96-c8de-4be8-9457-ca75ed1036db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"TransferVGG\",\"abnormal\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of TransferVGG model with abnormal label: \n",
            "0.7916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djrV2qLWxwnW",
        "colab_type": "code",
        "outputId": "98e456c2-9a88-4814-de3f-1db71f9961e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"TransferVGG\",\"acl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of TransferVGG model with acl label: \n",
            "0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M5KRRmexwvh",
        "colab_type": "code",
        "outputId": "382efc3f-7feb-40c4-a0d0-e20f17010b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ensemble_evaluate(\"TransferVGG\",\"meniscus\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting plane: axial\n",
            "Predicting plane: coronal\n",
            "Predicting plane: sagittal\n",
            "Accuracy of TransferVGG model with meniscus label: \n",
            "0.5833333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}